{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dibsdibsdibs/ISDA/blob/main/deep_PHISHYing_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIZV7kQ89GrR"
      },
      "source": [
        "\n",
        "# Prerequisites\n",
        "\n",
        "The following code imports the necessary libraries and modules for data analysis, visualization, traning, and testing of machine learning models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JRyKLP8uqns",
        "outputId": "eac8861c-1d6d-468e-f433-6ab01bed69a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.12.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.3.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.12.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "from collections import Counter\n",
        "from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\n",
        "from IPython.display import Image\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline\n",
        "!pip install scikeras\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stemmer=PorterStemmer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erfvkudcUubv"
      },
      "source": [
        "Import the dataset from github and read using pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "YudcMHJHwyek",
        "outputId": "60027f50-f5d7-460a-84ed-55858ca2c8dd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"msg_dataset\",\n  \"rows\": 3070,\n  \"fields\": [\n    {\n      \"column\": \"ADDRESS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1747,\n        \"samples\": [\n          \"+6395***27387\",\n          \"+6393***75272\",\n          \"+6396***38075\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MESSAGE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2546,\n        \"samples\": [\n          \"Get Free P288\\nCashback P15,888\\nURL: 688jili.com\",\n          \"JUAN C.  Dito sa SBET 100% CASINO WELCOME BONUS up to 888 + 3% Paymaya deposit bonus. Claim now at sbetChips1.com\",\n          \"JUAN C., DS88 Cockfighting is also available here in SBET, play here to win more prizes! Visit now and enjoy; sbetmanalo.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CLASSIFICATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Ham\",\n          \"Spam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CLASS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMISH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "msg_dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-46305fa1-56e9-4bce-aba2-20274065fc87\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADDRESS</th>\n",
              "      <th>MESSAGE</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>CLASS</th>\n",
              "      <th>SMISH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>+6391***88335</td>\n",
              "      <td>Loan?PMme</td>\n",
              "      <td>Spam</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TNT</td>\n",
              "      <td>You're trying to access sites not included in ...</td>\n",
              "      <td>Ham</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TNT</td>\n",
              "      <td>Para tuloy-tuloy ang saya with the tropa, umiw...</td>\n",
              "      <td>Ham</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TNT</td>\n",
              "      <td>LF: FREE Harry Styles Love On Tour concert tic...</td>\n",
              "      <td>Ham</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Eddy</td>\n",
              "      <td>nahihilo na ako punyeta</td>\n",
              "      <td>Ham</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>+6391***45143</td>\n",
              "      <td>JUAN C., Join WinPlus 2x Win Tournament! Win 4...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>+6390***48409</td>\n",
              "      <td>JUAN C., Join JPC: 100% up to 2k Welcome Bonus...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>+6392***01008</td>\n",
              "      <td>Discover Twitter! Go to m.twittercom/CNN for m...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>+6399***34987</td>\n",
              "      <td>Lucky Wheel's Mystery Bonus? http://phgaming.s...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>+6390***56711</td>\n",
              "      <td>Banco De Oro You're having issues with account...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46305fa1-56e9-4bce-aba2-20274065fc87')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46305fa1-56e9-4bce-aba2-20274065fc87 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46305fa1-56e9-4bce-aba2-20274065fc87');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-29aa7ff5-c521-4bf7-8830-402551594b3a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29aa7ff5-c521-4bf7-8830-402551594b3a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-29aa7ff5-c521-4bf7-8830-402551594b3a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         ADDRESS                                            MESSAGE  \\\n",
              "0  +6391***88335                                          Loan?PMme   \n",
              "1            TNT  You're trying to access sites not included in ...   \n",
              "2            TNT  Para tuloy-tuloy ang saya with the tropa, umiw...   \n",
              "3            TNT  LF: FREE Harry Styles Love On Tour concert tic...   \n",
              "4           Eddy                            nahihilo na ako punyeta   \n",
              "5  +6391***45143  JUAN C., Join WinPlus 2x Win Tournament! Win 4...   \n",
              "6  +6390***48409  JUAN C., Join JPC: 100% up to 2k Welcome Bonus...   \n",
              "7  +6392***01008  Discover Twitter! Go to m.twittercom/CNN for m...   \n",
              "8  +6399***34987  Lucky Wheel's Mystery Bonus? http://phgaming.s...   \n",
              "9  +6390***56711  Banco De Oro You're having issues with account...   \n",
              "\n",
              "  CLASSIFICATION  CLASS  SMISH  \n",
              "0           Spam      0      0  \n",
              "1            Ham      0      0  \n",
              "2            Ham      0      0  \n",
              "3            Ham      0      0  \n",
              "4            Ham      0      0  \n",
              "5           Spam      1      1  \n",
              "6           Spam      1      1  \n",
              "7           Spam      1      1  \n",
              "8           Spam      1      1  \n",
              "9           Spam      1      1  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "msg_url = 'https://raw.githubusercontent.com/dibsdibsdibs/ISDA/main/dataset.csv'\n",
        "msg_dataset = pd.read_csv(msg_url, encoding='latin-1')\n",
        "msg_dataset.head(n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzOHhZAHU5S0"
      },
      "source": [
        "The dataset includes over 3000 messages, almost half of them are spam messages and the rest are ham messages. The SMISH column identifies whether the data is smishing or just a spam message with no malicious intent - represented by 1 and 0, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxyFeBeO9Rud"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmQU3Tr1s5n1"
      },
      "source": [
        "## Text Preprocessing with CountVectorizer and Stop Words\n",
        "\n",
        "The presented code employs the CountVectorizer from sklearn.feature_extraction.text to preprocess textual data, particularly focusing on removing stop words from both English and Tagalog languages. Stop words represent the frequently used words in a language; there isn't a singular, universally accepted compilation of these words.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qk2zGyOXEO7f"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "tagalog_stop_words = [\n",
        "    'akin', 'aking', 'ako', 'alin', 'am', 'amin', 'aming', 'ang', 'ano', 'anumang',\n",
        "    'apat', 'at', 'atin', 'ating', 'ay', 'bababa', 'bago', 'bakit', 'bawat', 'bilang',\n",
        "    'dahil', 'dalawa', 'dapat', 'din', 'dito', 'doon', 'gagawin', 'gayunman', 'ginagawa',\n",
        "    'ginawa', 'ginawang', 'gumawa', 'gusto', 'habang', 'hanggang', 'hindi', 'huwag',\n",
        "    'iba', 'ibaba', 'ibabaw', 'ibig', 'ikaw', 'ilagay', 'ilalim', 'ilan', 'inyong',\n",
        "    'isa', 'isang', 'itaas', 'ito', 'iyo', 'iyon', 'iyong', 'ka', 'kahit', 'kailangan',\n",
        "    'kailanman', 'kami', 'kanila', 'kanilang', 'kanino', 'kanya', 'kanyang', 'kapag',\n",
        "    'kapwa', 'karamihan', 'katiyakan', 'katulad', 'kaya', 'kaysa', 'ko', 'kong', 'kulang',\n",
        "    'kumuha', 'kung', 'laban', 'lahat', 'lamang', 'likod', 'lima', 'maaari', 'maaaring',\n",
        "    'maging', 'mahusay', 'makita', 'marami', 'marapat', 'masyado', 'may', 'mayroon', 'mga',\n",
        "    'minsan', 'mismo', 'mula', 'muli', 'na', 'nabanggit', 'naging', 'nagkaroon', 'nais',\n",
        "    'nakita', 'namin', 'napaka', 'narito', 'nasaan', 'ng', 'ngayon', 'ni', 'nila', 'nilang',\n",
        "    'nito', 'niya', 'niyang', 'noon', 'o', 'pa', 'paano', 'pababa', 'paggawa', 'pagitan',\n",
        "    'pagkakaroon', 'pagkatapos', 'palabas', 'pamamagitan', 'panahon', 'pangalawa', 'para',\n",
        "    'paraan', 'pareho', 'pataas', 'pero', 'pumunta', 'pumupunta', 'sa', 'saan', 'sabi',\n",
        "    'sabihin', 'sarili', 'sila', 'sino', 'siya', 'tatlo', 'tayo', 'tulad', 'tungkol', 'una',\n",
        "    'walang', 'ba', 'eh', 'kasi', 'lang', 'mo', 'naman', 'opo', 'po', 'si', 'talaga', 'yung'\n",
        "]\n",
        "\n",
        "# Combine English and Tagalog stop words\n",
        "all_stop_words = list(ENGLISH_STOP_WORDS) + tagalog_stop_words\n",
        "\n",
        "#declare empty list to store tokenized message\n",
        "corpus=[]\n",
        "\n",
        "#iterate through the df[\"Message\"]\n",
        "for message in msg_dataset[\"MESSAGE\"]:\n",
        "\n",
        "    #replace every special characters, numbers etc.. with whitespace of message\n",
        "    #It will help retain only letter/alphabets\n",
        "    message=re.sub(\"[^a-zA-Z]\",\" \",message)\n",
        "\n",
        "    #convert every letters to its lowercase\n",
        "    message=message.lower()\n",
        "\n",
        "    #split the word into individual word list\n",
        "    message=message.split()\n",
        "\n",
        "    #perform stemming using PorterStemmer for all non-english-stopwords\n",
        "    message=[stemmer.stem(words)\n",
        "            for words in message\n",
        "             if words not in all_stop_words\n",
        "            ]\n",
        "    #join the word lists with the whitespace\n",
        "    message=\" \".join(message)\n",
        "\n",
        "    #append the message in corpus list\n",
        "    corpus.append(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "z3QpVe1t-2s2",
        "outputId": "3d889d66-8859-4290-f260-de811600c796"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"msg_dataset\",\n  \"rows\": 3070,\n  \"fields\": [\n    {\n      \"column\": \"ADDRESS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1747,\n        \"samples\": [\n          \"+6395***27387\",\n          \"+6393***75272\",\n          \"+6396***38075\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MESSAGE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2546,\n        \"samples\": [\n          \"Get Free P288\\nCashback P15,888\\nURL: 688jili.com\",\n          \"JUAN C.  Dito sa SBET 100% CASINO WELCOME BONUS up to 888 + 3% Paymaya deposit bonus. Claim now at sbetChips1.com\",\n          \"JUAN C., DS88 Cockfighting is also available here in SBET, play here to win more prizes! Visit now and enjoy; sbetmanalo.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CLASSIFICATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Ham\",\n          \"Spam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CLASS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMISH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LENGTH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 65,\n        \"min\": 3,\n        \"max\": 578,\n        \"num_unique_values\": 336,\n        \"samples\": [\n          128,\n          205\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "msg_dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-493f6391-cfb8-41cd-91d5-e3cdc6ee6a40\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADDRESS</th>\n",
              "      <th>MESSAGE</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>CLASS</th>\n",
              "      <th>SMISH</th>\n",
              "      <th>LENGTH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>+6391***88335</td>\n",
              "      <td>Loan?PMme</td>\n",
              "      <td>Spam</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TNT</td>\n",
              "      <td>You're trying to access sites not included in ...</td>\n",
              "      <td>Ham</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TNT</td>\n",
              "      <td>Para tuloy-tuloy ang saya with the tropa, umiw...</td>\n",
              "      <td>Ham</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TNT</td>\n",
              "      <td>LF: FREE Harry Styles Love On Tour concert tic...</td>\n",
              "      <td>Ham</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Eddy</td>\n",
              "      <td>nahihilo na ako punyeta</td>\n",
              "      <td>Ham</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>+6391***45143</td>\n",
              "      <td>JUAN C., Join WinPlus 2x Win Tournament! Win 4...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>+6390***48409</td>\n",
              "      <td>JUAN C., Join JPC: 100% up to 2k Welcome Bonus...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>+6392***01008</td>\n",
              "      <td>Discover Twitter! Go to m.twittercom/CNN for m...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>+6399***34987</td>\n",
              "      <td>Lucky Wheel's Mystery Bonus? http://phgaming.s...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>+6390***56711</td>\n",
              "      <td>Banco De Oro You're having issues with account...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-493f6391-cfb8-41cd-91d5-e3cdc6ee6a40')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-493f6391-cfb8-41cd-91d5-e3cdc6ee6a40 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-493f6391-cfb8-41cd-91d5-e3cdc6ee6a40');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b6e0b6a-45ab-4df4-a4e6-87ba459890c8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b6e0b6a-45ab-4df4-a4e6-87ba459890c8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b6e0b6a-45ab-4df4-a4e6-87ba459890c8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         ADDRESS                                            MESSAGE  \\\n",
              "0  +6391***88335                                          Loan?PMme   \n",
              "1            TNT  You're trying to access sites not included in ...   \n",
              "2            TNT  Para tuloy-tuloy ang saya with the tropa, umiw...   \n",
              "3            TNT  LF: FREE Harry Styles Love On Tour concert tic...   \n",
              "4           Eddy                            nahihilo na ako punyeta   \n",
              "5  +6391***45143  JUAN C., Join WinPlus 2x Win Tournament! Win 4...   \n",
              "6  +6390***48409  JUAN C., Join JPC: 100% up to 2k Welcome Bonus...   \n",
              "7  +6392***01008  Discover Twitter! Go to m.twittercom/CNN for m...   \n",
              "8  +6399***34987  Lucky Wheel's Mystery Bonus? http://phgaming.s...   \n",
              "9  +6390***56711  Banco De Oro You're having issues with account...   \n",
              "\n",
              "  CLASSIFICATION  CLASS  SMISH  LENGTH  \n",
              "0           Spam      0      0       9  \n",
              "1            Ham      0      0      92  \n",
              "2            Ham      0      0     202  \n",
              "3            Ham      0      0     288  \n",
              "4            Ham      0      0      23  \n",
              "5           Spam      1      1     130  \n",
              "6           Spam      1      1      96  \n",
              "7           Spam      1      1     117  \n",
              "8           Spam      1      1      93  \n",
              "9           Spam      1      1     100  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "msg_dataset[\"LENGTH\"] = msg_dataset[\"MESSAGE\"].apply(len)\n",
        "msg_dataset.head(n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_V3jblhAFJc"
      },
      "source": [
        "# Spam vs Ham Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlCwPZ2K1-A-"
      },
      "source": [
        "## Long Short Term Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPILHMCzJPvt",
        "outputId": "18aaa211-ce8f-43e9-b652-271ac91fff26"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stemmer=PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jFNdVtIDJY8I"
      },
      "outputs": [],
      "source": [
        "#declare empty list to store tokenized message\n",
        "corpus=[]\n",
        "\n",
        "#iterate through the df[\"Message\"]\n",
        "for message in msg_dataset[\"MESSAGE\"]:\n",
        "\n",
        "    #replace every special characters, numbers etc.. with whitespace of message\n",
        "    #It will help retain only letter/alphabets\n",
        "    message=re.sub(\"[^a-zA-Z]\",\" \",message)\n",
        "\n",
        "    #convert every letters to its lowercase\n",
        "    message=message.lower()\n",
        "\n",
        "    #split the word into individual word list\n",
        "    message=message.split()\n",
        "\n",
        "    #perform stemming using PorterStemmer for all non-english-stopwords\n",
        "    message=[stemmer.stem(words)\n",
        "            for words in message\n",
        "             if words not in all_stop_words\n",
        "            ]\n",
        "    #join the word lists with the whitespace\n",
        "    message=\" \".join(message)\n",
        "\n",
        "    #append the message in corpus list\n",
        "    corpus.append(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "B5FmPtz92Gzg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "6j1tiZaq9WXd",
        "outputId": "d8b6c05a-d450-4eff-cb74-e20f7b271fcf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"msg_dataset\",\n  \"rows\": 3070,\n  \"fields\": [\n    {\n      \"column\": \"ADDRESS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1747,\n        \"samples\": [\n          \"+6395***27387\",\n          \"+6393***75272\",\n          \"+6396***38075\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MESSAGE\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2546,\n        \"samples\": [\n          \"Get Free P288\\nCashback P15,888\\nURL: 688jili.com\",\n          \"JUAN C.  Dito sa SBET 100% CASINO WELCOME BONUS up to 888 + 3% Paymaya deposit bonus. Claim now at sbetChips1.com\",\n          \"JUAN C., DS88 Cockfighting is also available here in SBET, play here to win more prizes! Visit now and enjoy; sbetmanalo.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CLASSIFICATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Ham\",\n          \"Spam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CLASS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMISH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LENGTH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 65,\n        \"min\": 3,\n        \"max\": 578,\n        \"num_unique_values\": 336,\n        \"samples\": [\n          128,\n          205\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "msg_dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a1a2bdd9-e388-4b20-a1ce-49f27dcc8f72\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADDRESS</th>\n",
              "      <th>MESSAGE</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>CLASS</th>\n",
              "      <th>SMISH</th>\n",
              "      <th>LENGTH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>+6391***88335</td>\n",
              "      <td>Loan?PMme</td>\n",
              "      <td>Spam</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TNT</td>\n",
              "      <td>You're trying to access sites not included in ...</td>\n",
              "      <td>Ham</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TNT</td>\n",
              "      <td>Para tuloy-tuloy ang saya with the tropa, umiw...</td>\n",
              "      <td>Ham</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TNT</td>\n",
              "      <td>LF: FREE Harry Styles Love On Tour concert tic...</td>\n",
              "      <td>Ham</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Eddy</td>\n",
              "      <td>nahihilo na ako punyeta</td>\n",
              "      <td>Ham</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>+6391***45143</td>\n",
              "      <td>JUAN C., Join WinPlus 2x Win Tournament! Win 4...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>+6390***48409</td>\n",
              "      <td>JUAN C., Join JPC: 100% up to 2k Welcome Bonus...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>+6392***01008</td>\n",
              "      <td>Discover Twitter! Go to m.twittercom/CNN for m...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>+6399***34987</td>\n",
              "      <td>Lucky Wheel's Mystery Bonus? http://phgaming.s...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>+6390***56711</td>\n",
              "      <td>Banco De Oro You're having issues with account...</td>\n",
              "      <td>Spam</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1a2bdd9-e388-4b20-a1ce-49f27dcc8f72')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1a2bdd9-e388-4b20-a1ce-49f27dcc8f72 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1a2bdd9-e388-4b20-a1ce-49f27dcc8f72');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a35e3e2-7cc4-457b-90fb-91464e739bc8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a35e3e2-7cc4-457b-90fb-91464e739bc8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a35e3e2-7cc4-457b-90fb-91464e739bc8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         ADDRESS                                            MESSAGE  \\\n",
              "0  +6391***88335                                          Loan?PMme   \n",
              "1            TNT  You're trying to access sites not included in ...   \n",
              "2            TNT  Para tuloy-tuloy ang saya with the tropa, umiw...   \n",
              "3            TNT  LF: FREE Harry Styles Love On Tour concert tic...   \n",
              "4           Eddy                            nahihilo na ako punyeta   \n",
              "5  +6391***45143  JUAN C., Join WinPlus 2x Win Tournament! Win 4...   \n",
              "6  +6390***48409  JUAN C., Join JPC: 100% up to 2k Welcome Bonus...   \n",
              "7  +6392***01008  Discover Twitter! Go to m.twittercom/CNN for m...   \n",
              "8  +6399***34987  Lucky Wheel's Mystery Bonus? http://phgaming.s...   \n",
              "9  +6390***56711  Banco De Oro You're having issues with account...   \n",
              "\n",
              "  CLASSIFICATION  CLASS  SMISH  LENGTH  \n",
              "0           Spam      0      0       9  \n",
              "1            Ham      0      0      92  \n",
              "2            Ham      0      0     202  \n",
              "3            Ham      0      0     288  \n",
              "4            Ham      0      0      23  \n",
              "5           Spam      1      1     130  \n",
              "6           Spam      1      1      96  \n",
              "7           Spam      1      1     117  \n",
              "8           Spam      1      1      93  \n",
              "9           Spam      1      1     100  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "msg_dataset[\"LENGTH\"] = msg_dataset[\"MESSAGE\"].apply(len)\n",
        "msg_dataset.head(n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rrXmWlkXVMy"
      },
      "source": [
        "### Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lm-CA0pdu2O"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2NPMaqTdTwD"
      },
      "outputs": [],
      "source": [
        "vocab_size=10000\n",
        "\n",
        "oneHot_doc=[one_hot(words,n=vocab_size) for words in corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8VQSJodfxck"
      },
      "outputs": [],
      "source": [
        "sentence_len=200\n",
        "embedded_doc=pad_sequences(\n",
        "    oneHot_doc,\n",
        "    maxlen=sentence_len,\n",
        "    padding=\"pre\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPZHqTQDf1iX"
      },
      "outputs": [],
      "source": [
        "extract_features=pd.DataFrame(data=embedded_doc)\n",
        "target=msg_dataset[\"CLASS\"]\n",
        "msg_dataset_final=pd.concat([extract_features,target],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0mCau8tf5eN"
      },
      "outputs": [],
      "source": [
        "X = msg_dataset_final.drop(\"CLASS\",axis=1)\n",
        "y = msg_dataset_final[\"CLASS\"]\n",
        "\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, random_state=42, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seI2xkn8ddLC"
      },
      "outputs": [],
      "source": [
        "def lstm_model(vocab_size=10000, feature_num=100, sentence_len=200, mem_cells=128, learning_rate=0.001, dropout_rate=0.2, optimizer='Adam'):\n",
        "  model=Sequential()\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=feature_num, input_length=sentence_len))\n",
        "  model.add(LSTM(units=mem_cells, dropout=dropout_rate))\n",
        "  model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "  model.compile(optimizer=optimizer(learning_rate=learning_rate), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdWclS0jWaBe"
      },
      "outputs": [],
      "source": [
        "class KerasClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, vocab_size=10000, feature_num=100, sentence_len=200, mem_cells=128, learning_rate=0.001, dropout_rate=0.2, optimizer='Adam'):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.feature_num = feature_num\n",
        "        self.sentence_len = sentence_len\n",
        "        self.mem_cells = mem_cells\n",
        "        self.learning_rate = learning_rate\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.optimizer = optimizer\n",
        "        self.model = self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(input_dim=self.vocab_size, output_dim=self.feature_num, input_length=self.sentence_len))\n",
        "        model.add(LSTM(units=self.mem_cells, dropout=self.dropout_rate))\n",
        "        model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "        # Map optimizer string to optimizer class\n",
        "        optimizer_classes = {'Adam': Adam}  # You can add more optimizers as needed\n",
        "        optimizer_class = optimizer_classes.get(self.optimizer, None)\n",
        "\n",
        "        if optimizer_class is None:\n",
        "            raise ValueError(f\"Unsupported optimizer: {self.optimizer}\")\n",
        "\n",
        "        optimizer_instance = optimizer_class(learning_rate=self.learning_rate)\n",
        "        model.compile(optimizer=optimizer_instance, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model.fit(X, y, epochs=10, validation_split=0.15, verbose=1)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred_proba = self.model.predict(X)\n",
        "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "        return y_pred\n",
        "\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        return accuracy_score(y, y_pred), precision_score(y, y_pred), recall_score(y, y_pred), confusion_matrix(y, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TFPNgl9TJ_l",
        "outputId": "f8d52525-85e3-4c06-ca33-7be554310213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 19s 439ms/step - loss: 0.6237 - accuracy: 0.6655 - val_loss: 0.4019 - val_accuracy: 0.8649\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 18s 659ms/step - loss: 0.2713 - accuracy: 0.9137 - val_loss: 4.6829 - val_accuracy: 0.5338\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 12s 442ms/step - loss: 2.4962 - accuracy: 0.5803 - val_loss: 0.4740 - val_accuracy: 0.7703\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.2757 - accuracy: 0.8873 - val_loss: 0.2216 - val_accuracy: 0.9122\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 8s 309ms/step - loss: 0.1901 - accuracy: 0.9341 - val_loss: 0.1978 - val_accuracy: 0.9189\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.1409 - accuracy: 0.9472 - val_loss: 0.1426 - val_accuracy: 0.9797\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 11s 429ms/step - loss: 1.1380 - accuracy: 0.6271 - val_loss: 1.2819 - val_accuracy: 0.5338\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 9s 350ms/step - loss: 0.9035 - accuracy: 0.5192 - val_loss: 0.6365 - val_accuracy: 0.5541\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 301ms/step - loss: 0.5269 - accuracy: 0.6942 - val_loss: 0.4872 - val_accuracy: 0.7838\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.3901 - accuracy: 0.8849 - val_loss: 0.3840 - val_accuracy: 0.8446\n",
            "31/31 [==============================] - 3s 91ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 354ms/step - loss: 0.5944 - accuracy: 0.7554 - val_loss: 0.4131 - val_accuracy: 0.7973\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 10s 382ms/step - loss: 0.8425 - accuracy: 0.8369 - val_loss: 0.2389 - val_accuracy: 0.9189\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.1517 - accuracy: 0.9676 - val_loss: 0.1925 - val_accuracy: 0.9189\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 9s 335ms/step - loss: 0.0877 - accuracy: 0.9796 - val_loss: 0.1173 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 322ms/step - loss: 0.0516 - accuracy: 0.9832 - val_loss: 0.1102 - val_accuracy: 0.9595\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.0380 - accuracy: 0.9892 - val_loss: 0.1066 - val_accuracy: 0.9662\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0321 - accuracy: 0.9916 - val_loss: 0.1055 - val_accuracy: 0.9595\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 8s 313ms/step - loss: 0.0211 - accuracy: 0.9952 - val_loss: 0.1115 - val_accuracy: 0.9595\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 351ms/step - loss: 0.0156 - accuracy: 0.9964 - val_loss: 0.1103 - val_accuracy: 0.9527\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.0148 - accuracy: 0.9976 - val_loss: 0.1119 - val_accuracy: 0.9527\n",
            "31/31 [==============================] - 3s 92ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 327ms/step - loss: 0.6155 - accuracy: 0.7578 - val_loss: 0.3726 - val_accuracy: 0.8378\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.3128 - accuracy: 0.9281 - val_loss: 0.2192 - val_accuracy: 0.9392\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.1158 - accuracy: 0.9688 - val_loss: 0.1202 - val_accuracy: 0.9527\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 9s 353ms/step - loss: 0.0540 - accuracy: 0.9892 - val_loss: 0.0788 - val_accuracy: 0.9730\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 313ms/step - loss: 0.0309 - accuracy: 0.9928 - val_loss: 0.0806 - val_accuracy: 0.9730\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.1008 - val_accuracy: 0.9662\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.0222 - accuracy: 0.9964 - val_loss: 0.0712 - val_accuracy: 0.9797\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 8s 310ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9865\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 346ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.0636 - val_accuracy: 0.9797\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 354ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.0518 - val_accuracy: 0.9797\n",
            "31/31 [==============================] - 3s 94ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 333ms/step - loss: 0.6444 - accuracy: 0.6894 - val_loss: 0.5456 - val_accuracy: 0.7703\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.3218 - accuracy: 0.8993 - val_loss: 0.1690 - val_accuracy: 0.9527\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 353ms/step - loss: 0.0871 - accuracy: 0.9760 - val_loss: 0.1221 - val_accuracy: 0.9257\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 9s 335ms/step - loss: 0.0433 - accuracy: 0.9820 - val_loss: 0.1127 - val_accuracy: 0.9459\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 317ms/step - loss: 0.0314 - accuracy: 0.9928 - val_loss: 0.0983 - val_accuracy: 0.9595\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.0456 - accuracy: 0.9856 - val_loss: 0.1601 - val_accuracy: 0.9257\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.0501 - accuracy: 0.9844 - val_loss: 0.1075 - val_accuracy: 0.9595\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 8s 315ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 0.1014 - val_accuracy: 0.9662\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.1055 - val_accuracy: 0.9595\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.1093 - val_accuracy: 0.9662\n",
            "31/31 [==============================] - 3s 94ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 374ms/step - loss: 0.6042 - accuracy: 0.7122 - val_loss: 0.4356 - val_accuracy: 0.8176\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 308ms/step - loss: 0.4531 - accuracy: 0.9101 - val_loss: 0.1693 - val_accuracy: 0.9595\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.1457 - accuracy: 0.9724 - val_loss: 0.1557 - val_accuracy: 0.9392\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.0871 - accuracy: 0.9772 - val_loss: 0.1281 - val_accuracy: 0.9392\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 325ms/step - loss: 0.0581 - accuracy: 0.9856 - val_loss: 0.1107 - val_accuracy: 0.9662\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 332ms/step - loss: 0.0383 - accuracy: 0.9868 - val_loss: 0.1286 - val_accuracy: 0.9257\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 367ms/step - loss: 0.0327 - accuracy: 0.9904 - val_loss: 0.1033 - val_accuracy: 0.9459\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 367ms/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.1192 - val_accuracy: 0.9392\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.0343 - accuracy: 0.9892 - val_loss: 0.0816 - val_accuracy: 0.9662\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0311 - accuracy: 0.9940 - val_loss: 0.0930 - val_accuracy: 0.9662\n",
            "31/31 [==============================] - 3s 93ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 330ms/step - loss: 0.6220 - accuracy: 0.7266 - val_loss: 0.4699 - val_accuracy: 0.8108\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.2596 - accuracy: 0.9185 - val_loss: 0.1424 - val_accuracy: 0.9527\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.1271 - accuracy: 0.9628 - val_loss: 0.1140 - val_accuracy: 0.9595\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 9s 338ms/step - loss: 0.0616 - accuracy: 0.9820 - val_loss: 0.1045 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 305ms/step - loss: 0.0622 - accuracy: 0.9832 - val_loss: 0.1235 - val_accuracy: 0.9392\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.0340 - accuracy: 0.9952 - val_loss: 0.1222 - val_accuracy: 0.9324\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.1077 - val_accuracy: 0.9595\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 8s 310ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9527\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 351ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.1176 - val_accuracy: 0.9595\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.1143 - val_accuracy: 0.9527\n",
            "31/31 [==============================] - 3s 93ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 382ms/step - loss: 0.6035 - accuracy: 0.6930 - val_loss: 0.3394 - val_accuracy: 0.8851\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 309ms/step - loss: 1.2243 - accuracy: 0.8106 - val_loss: 0.1941 - val_accuracy: 0.9527\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.2078 - accuracy: 0.9544 - val_loss: 0.2274 - val_accuracy: 0.9257\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.1267 - accuracy: 0.9664 - val_loss: 0.1664 - val_accuracy: 0.9324\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 319ms/step - loss: 0.0746 - accuracy: 0.9868 - val_loss: 0.1421 - val_accuracy: 0.9459\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 336ms/step - loss: 0.0463 - accuracy: 0.9904 - val_loss: 0.1164 - val_accuracy: 0.9595\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.0347 - accuracy: 0.9904 - val_loss: 0.0987 - val_accuracy: 0.9595\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.0264 - accuracy: 0.9940 - val_loss: 0.1027 - val_accuracy: 0.9527\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 310ms/step - loss: 0.0222 - accuracy: 0.9916 - val_loss: 0.0962 - val_accuracy: 0.9527\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.0176 - accuracy: 0.9964 - val_loss: 0.0992 - val_accuracy: 0.9595\n",
            "31/31 [==============================] - 4s 133ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 381ms/step - loss: 0.5853 - accuracy: 0.7002 - val_loss: 0.3915 - val_accuracy: 0.8243\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 305ms/step - loss: 0.2640 - accuracy: 0.9137 - val_loss: 0.1663 - val_accuracy: 0.9324\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0980 - accuracy: 0.9748 - val_loss: 0.1211 - val_accuracy: 0.9459\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.0434 - accuracy: 0.9832 - val_loss: 0.1351 - val_accuracy: 0.9189\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 316ms/step - loss: 0.0336 - accuracy: 0.9880 - val_loss: 0.1288 - val_accuracy: 0.9392\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 347ms/step - loss: 0.0216 - accuracy: 0.9916 - val_loss: 0.1162 - val_accuracy: 0.9392\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 0.0395 - accuracy: 0.9844 - val_loss: 0.1490 - val_accuracy: 0.9527\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0824 - accuracy: 0.9808 - val_loss: 0.1286 - val_accuracy: 0.9459\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.0249 - accuracy: 0.9988 - val_loss: 0.1100 - val_accuracy: 0.9595\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 0.0973 - val_accuracy: 0.9527\n",
            "31/31 [==============================] - 5s 137ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 374ms/step - loss: 0.6274 - accuracy: 0.7278 - val_loss: 0.3898 - val_accuracy: 0.8446\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.4029 - accuracy: 0.8693 - val_loss: 0.2045 - val_accuracy: 0.9324\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.1537 - accuracy: 0.9688 - val_loss: 0.1698 - val_accuracy: 0.9662\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0978 - accuracy: 0.9832 - val_loss: 0.1225 - val_accuracy: 0.9662\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 342ms/step - loss: 0.0610 - accuracy: 0.9880 - val_loss: 0.0989 - val_accuracy: 0.9865\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 311ms/step - loss: 0.0421 - accuracy: 0.9904 - val_loss: 0.0833 - val_accuracy: 0.9865\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 369ms/step - loss: 0.0312 - accuracy: 0.9928 - val_loss: 0.0958 - val_accuracy: 0.9730\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.0335 - accuracy: 0.9904 - val_loss: 0.0739 - val_accuracy: 0.9865\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.0729 - val_accuracy: 0.9797\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 346ms/step - loss: 0.0174 - accuracy: 0.9964 - val_loss: 0.0691 - val_accuracy: 0.9797\n",
            "31/31 [==============================] - 5s 135ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 375ms/step - loss: 0.6066 - accuracy: 0.7098 - val_loss: 0.3851 - val_accuracy: 0.8378\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 307ms/step - loss: 0.2268 - accuracy: 0.9245 - val_loss: 0.1349 - val_accuracy: 0.9527\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0806 - accuracy: 0.9832 - val_loss: 0.1468 - val_accuracy: 0.9257\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0681 - accuracy: 0.9760 - val_loss: 0.1041 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 339ms/step - loss: 0.0336 - accuracy: 0.9916 - val_loss: 0.0941 - val_accuracy: 0.9595\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 315ms/step - loss: 0.0218 - accuracy: 0.9916 - val_loss: 0.0873 - val_accuracy: 0.9595\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.0863 - val_accuracy: 0.9730\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.0871 - val_accuracy: 0.9730\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 315ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9662\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 347ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.0880 - val_accuracy: 0.9730\n",
            "31/31 [==============================] - 5s 133ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 383ms/step - loss: 0.6150 - accuracy: 0.7026 - val_loss: 0.4099 - val_accuracy: 0.8311\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.3200 - accuracy: 0.9113 - val_loss: 0.1733 - val_accuracy: 0.9595\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.1249 - accuracy: 0.9748 - val_loss: 0.1176 - val_accuracy: 0.9730\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.0566 - accuracy: 0.9844 - val_loss: 0.0798 - val_accuracy: 0.9865\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 346ms/step - loss: 0.0334 - accuracy: 0.9928 - val_loss: 0.0800 - val_accuracy: 0.9662\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 311ms/step - loss: 0.0267 - accuracy: 0.9892 - val_loss: 0.0810 - val_accuracy: 0.9730\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 367ms/step - loss: 0.0189 - accuracy: 0.9928 - val_loss: 0.0725 - val_accuracy: 0.9662\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 0.0711 - val_accuracy: 0.9662\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 310ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.0672 - val_accuracy: 0.9662\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 343ms/step - loss: 0.0094 - accuracy: 0.9988 - val_loss: 0.0730 - val_accuracy: 0.9662\n",
            "31/31 [==============================] - 4s 103ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 11s 331ms/step - loss: 0.6150 - accuracy: 0.7278 - val_loss: 0.4641 - val_accuracy: 0.8041\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 343ms/step - loss: 0.2998 - accuracy: 0.9041 - val_loss: 0.1852 - val_accuracy: 0.9324\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.1241 - accuracy: 0.9712 - val_loss: 0.1668 - val_accuracy: 0.9392\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0758 - accuracy: 0.9844 - val_loss: 0.1197 - val_accuracy: 0.9459\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 8s 312ms/step - loss: 0.0406 - accuracy: 0.9856 - val_loss: 0.1059 - val_accuracy: 0.9459\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 367ms/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0992 - val_accuracy: 0.9595\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0182 - accuracy: 0.9928 - val_loss: 0.1056 - val_accuracy: 0.9595\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.0997 - val_accuracy: 0.9595\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 316ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 0.1015 - val_accuracy: 0.9595\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 373ms/step - loss: 0.0126 - accuracy: 0.9940 - val_loss: 0.1178 - val_accuracy: 0.9527\n",
            "31/31 [==============================] - 5s 138ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 375ms/step - loss: 0.6270 - accuracy: 0.6859 - val_loss: 0.4744 - val_accuracy: 0.8243\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.2636 - accuracy: 0.9137 - val_loss: 0.1753 - val_accuracy: 0.9459\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.1143 - accuracy: 0.9736 - val_loss: 0.1315 - val_accuracy: 0.9527\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.6588 - accuracy: 0.8465 - val_loss: 0.4055 - val_accuracy: 0.8108\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 341ms/step - loss: 0.1913 - accuracy: 0.9604 - val_loss: 0.2440 - val_accuracy: 0.9122\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 316ms/step - loss: 0.0883 - accuracy: 0.9892 - val_loss: 0.1533 - val_accuracy: 0.9392\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.0477 - accuracy: 0.9940 - val_loss: 0.1243 - val_accuracy: 0.9595\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.0293 - accuracy: 0.9952 - val_loss: 0.0923 - val_accuracy: 0.9797\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 370ms/step - loss: 0.0239 - accuracy: 0.9976 - val_loss: 0.1138 - val_accuracy: 0.9527\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 330ms/step - loss: 0.0166 - accuracy: 0.9988 - val_loss: 0.0824 - val_accuracy: 0.9662\n",
            "31/31 [==============================] - 5s 136ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 381ms/step - loss: 0.6208 - accuracy: 0.7338 - val_loss: 0.4690 - val_accuracy: 0.7635\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.2686 - accuracy: 0.9017 - val_loss: 0.1797 - val_accuracy: 0.9324\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.1064 - accuracy: 0.9724 - val_loss: 0.1260 - val_accuracy: 0.9595\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0486 - accuracy: 0.9880 - val_loss: 0.1139 - val_accuracy: 0.9527\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 0.1363 - val_accuracy: 0.9459\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 316ms/step - loss: 0.0226 - accuracy: 0.9940 - val_loss: 0.1223 - val_accuracy: 0.9392\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 0.1293 - val_accuracy: 0.9459\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.0290 - accuracy: 0.9952 - val_loss: 0.1034 - val_accuracy: 0.9595\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 337ms/step - loss: 0.0273 - accuracy: 0.9988 - val_loss: 0.0980 - val_accuracy: 0.9595\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 318ms/step - loss: 0.0105 - accuracy: 0.9988 - val_loss: 0.0993 - val_accuracy: 0.9662\n",
            "31/31 [==============================] - 4s 119ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 11s 342ms/step - loss: 0.6226 - accuracy: 0.6739 - val_loss: 0.4103 - val_accuracy: 0.8649\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 334ms/step - loss: 0.2447 - accuracy: 0.9221 - val_loss: 0.1891 - val_accuracy: 0.9122\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 353ms/step - loss: 0.1307 - accuracy: 0.9496 - val_loss: 0.1049 - val_accuracy: 0.9595\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.0650 - accuracy: 0.9796 - val_loss: 0.1484 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 8s 312ms/step - loss: 0.0397 - accuracy: 0.9940 - val_loss: 0.0732 - val_accuracy: 0.9662\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.0209 - accuracy: 0.9952 - val_loss: 0.0673 - val_accuracy: 0.9730\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.0148 - accuracy: 0.9940 - val_loss: 0.0726 - val_accuracy: 0.9730\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 370ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.0718 - val_accuracy: 0.9730\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 311ms/step - loss: 0.0109 - accuracy: 0.9952 - val_loss: 0.0673 - val_accuracy: 0.9730\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.0594 - val_accuracy: 0.9730\n",
            "31/31 [==============================] - 4s 122ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 380ms/step - loss: 0.5584 - accuracy: 0.7770 - val_loss: 0.4027 - val_accuracy: 0.8041\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 306ms/step - loss: 0.1950 - accuracy: 0.9365 - val_loss: 0.1313 - val_accuracy: 0.9527\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.0871 - accuracy: 0.9760 - val_loss: 0.1174 - val_accuracy: 0.9527\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.0559 - accuracy: 0.9772 - val_loss: 0.0996 - val_accuracy: 0.9527\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 8s 312ms/step - loss: 0.0355 - accuracy: 0.9868 - val_loss: 0.0958 - val_accuracy: 0.9595\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 345ms/step - loss: 0.0216 - accuracy: 0.9916 - val_loss: 0.0886 - val_accuracy: 0.9595\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 9s 353ms/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 0.0890 - val_accuracy: 0.9662\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.0925 - val_accuracy: 0.9527\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 315ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1068 - val_accuracy: 0.9527\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.0317 - accuracy: 0.9916 - val_loss: 0.1025 - val_accuracy: 0.9595\n",
            "31/31 [==============================] - 5s 137ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 380ms/step - loss: 0.6162 - accuracy: 0.6799 - val_loss: 0.3932 - val_accuracy: 0.8514\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 308ms/step - loss: 0.2384 - accuracy: 0.9245 - val_loss: 0.1502 - val_accuracy: 0.9392\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0851 - accuracy: 0.9760 - val_loss: 0.1254 - val_accuracy: 0.9527\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.0483 - accuracy: 0.9868 - val_loss: 0.1160 - val_accuracy: 0.9662\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 376ms/step - loss: 0.0327 - accuracy: 0.9892 - val_loss: 0.0904 - val_accuracy: 0.9662\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 317ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.0775 - val_accuracy: 0.9662\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 0.0825 - val_accuracy: 0.9662\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.0959 - val_accuracy: 0.9662\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0103 - accuracy: 0.9952 - val_loss: 0.0734 - val_accuracy: 0.9662\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 8s 313ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0783 - val_accuracy: 0.9730\n",
            "31/31 [==============================] - 5s 136ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 362ms/step - loss: 0.6009 - accuracy: 0.7458 - val_loss: 0.4670 - val_accuracy: 0.7635\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 314ms/step - loss: 0.2592 - accuracy: 0.8981 - val_loss: 0.1591 - val_accuracy: 0.9392\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.1042 - accuracy: 0.9688 - val_loss: 0.1303 - val_accuracy: 0.9324\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 369ms/step - loss: 0.0787 - accuracy: 0.9808 - val_loss: 0.1127 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 316ms/step - loss: 0.0367 - accuracy: 0.9904 - val_loss: 0.1096 - val_accuracy: 0.9459\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 343ms/step - loss: 0.0617 - accuracy: 0.9760 - val_loss: 0.1198 - val_accuracy: 0.9257\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.0241 - accuracy: 0.9952 - val_loss: 0.1013 - val_accuracy: 0.9662\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.0127 - accuracy: 0.9988 - val_loss: 0.1052 - val_accuracy: 0.9595\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 306ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.1029 - val_accuracy: 0.9459\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0781 - accuracy: 0.9832 - val_loss: 0.1866 - val_accuracy: 0.9324\n",
            "31/31 [==============================] - 5s 137ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 14s 439ms/step - loss: 0.6153 - accuracy: 0.6918 - val_loss: 0.4460 - val_accuracy: 0.7838\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.2560 - accuracy: 0.9089 - val_loss: 0.1615 - val_accuracy: 0.9595\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 349ms/step - loss: 0.0920 - accuracy: 0.9688 - val_loss: 0.1161 - val_accuracy: 0.9392\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.0650 - accuracy: 0.9820 - val_loss: 0.0961 - val_accuracy: 0.9662\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0368 - accuracy: 0.9904 - val_loss: 0.0703 - val_accuracy: 0.9797\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 8s 312ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.0743 - val_accuracy: 0.9730\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0709 - val_accuracy: 0.9797\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 367ms/step - loss: 0.0141 - accuracy: 0.9940 - val_loss: 0.0796 - val_accuracy: 0.9730\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 0.0709 - val_accuracy: 0.9730\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 8s 313ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0637 - val_accuracy: 0.9730\n",
            "31/31 [==============================] - 4s 132ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 13s 408ms/step - loss: 0.6083 - accuracy: 0.7110 - val_loss: 0.4010 - val_accuracy: 0.8446\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 341ms/step - loss: 0.2303 - accuracy: 0.9149 - val_loss: 0.1546 - val_accuracy: 0.9324\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 330ms/step - loss: 0.0856 - accuracy: 0.9808 - val_loss: 0.1206 - val_accuracy: 0.9595\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0500 - accuracy: 0.9844 - val_loss: 0.1101 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0267 - accuracy: 0.9880 - val_loss: 0.1005 - val_accuracy: 0.9730\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 321ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.0992 - val_accuracy: 0.9730\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 351ms/step - loss: 0.7901 - accuracy: 0.8633 - val_loss: 0.7818 - val_accuracy: 0.7973\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.3715 - accuracy: 0.8525 - val_loss: 0.2520 - val_accuracy: 0.8784\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 369ms/step - loss: 0.1543 - accuracy: 0.9556 - val_loss: 0.1970 - val_accuracy: 0.9122\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 8s 308ms/step - loss: 0.0965 - accuracy: 0.9736 - val_loss: 0.1688 - val_accuracy: 0.9392\n",
            "31/31 [==============================] - 4s 117ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 13s 387ms/step - loss: 0.6115 - accuracy: 0.7194 - val_loss: 0.3701 - val_accuracy: 0.8716\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 326ms/step - loss: 0.2139 - accuracy: 0.9293 - val_loss: 0.1557 - val_accuracy: 0.9392\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 337ms/step - loss: 0.1233 - accuracy: 0.9544 - val_loss: 0.1419 - val_accuracy: 0.9189\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0794 - accuracy: 0.9760 - val_loss: 0.1196 - val_accuracy: 0.9730\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0466 - accuracy: 0.9904 - val_loss: 0.0813 - val_accuracy: 0.9662\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 318ms/step - loss: 0.0277 - accuracy: 0.9928 - val_loss: 0.0681 - val_accuracy: 0.9797\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0602 - val_accuracy: 0.9865\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 369ms/step - loss: 0.0151 - accuracy: 0.9940 - val_loss: 0.0584 - val_accuracy: 0.9865\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.0547 - val_accuracy: 0.9865\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 8s 309ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 0.0618 - val_accuracy: 0.9730\n",
            "31/31 [==============================] - 4s 115ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 384ms/step - loss: 0.5976 - accuracy: 0.7518 - val_loss: 0.3897 - val_accuracy: 0.8176\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 323ms/step - loss: 0.2089 - accuracy: 0.9317 - val_loss: 0.1304 - val_accuracy: 0.9527\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 335ms/step - loss: 0.0768 - accuracy: 0.9772 - val_loss: 0.1375 - val_accuracy: 0.9527\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0742 - accuracy: 0.9820 - val_loss: 0.1227 - val_accuracy: 0.9392\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.0446 - accuracy: 0.9892 - val_loss: 0.0949 - val_accuracy: 0.9595\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 316ms/step - loss: 0.0255 - accuracy: 0.9940 - val_loss: 0.0844 - val_accuracy: 0.9662\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.0929 - val_accuracy: 0.9595\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.0139 - accuracy: 0.9988 - val_loss: 0.0837 - val_accuracy: 0.9662\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 380ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 0.1018 - val_accuracy: 0.9595\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 316ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9595\n",
            "31/31 [==============================] - 5s 137ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 384ms/step - loss: 0.6128 - accuracy: 0.7458 - val_loss: 0.3781 - val_accuracy: 0.8716\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 311ms/step - loss: 0.2528 - accuracy: 0.9233 - val_loss: 0.2274 - val_accuracy: 0.9595\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.1353 - accuracy: 0.9652 - val_loss: 0.1172 - val_accuracy: 0.9730\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0619 - accuracy: 0.9856 - val_loss: 0.0839 - val_accuracy: 0.9797\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.0527 - accuracy: 0.9940 - val_loss: 0.1043 - val_accuracy: 0.9662\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 316ms/step - loss: 0.0220 - accuracy: 0.9940 - val_loss: 0.0620 - val_accuracy: 0.9865\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0156 - accuracy: 0.9940 - val_loss: 0.0685 - val_accuracy: 0.9797\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.0699 - val_accuracy: 0.9797\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0339 - accuracy: 0.9880 - val_loss: 0.1181 - val_accuracy: 0.9459\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 8s 309ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9595\n",
            "31/31 [==============================] - 4s 124ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 13s 383ms/step - loss: 0.6200 - accuracy: 0.7254 - val_loss: 0.5179 - val_accuracy: 0.7297\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 326ms/step - loss: 0.3776 - accuracy: 0.8681 - val_loss: 0.2248 - val_accuracy: 0.9257\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 328ms/step - loss: 0.1237 - accuracy: 0.9640 - val_loss: 0.1226 - val_accuracy: 0.9527\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 9s 350ms/step - loss: 0.0625 - accuracy: 0.9796 - val_loss: 0.1179 - val_accuracy: 0.9527\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.0484 - accuracy: 0.9844 - val_loss: 0.1069 - val_accuracy: 0.9595\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 8s 312ms/step - loss: 0.0298 - accuracy: 0.9916 - val_loss: 0.0980 - val_accuracy: 0.9595\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 9s 353ms/step - loss: 0.0194 - accuracy: 0.9952 - val_loss: 0.0935 - val_accuracy: 0.9662\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.0138 - accuracy: 0.9976 - val_loss: 0.1131 - val_accuracy: 0.9527\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 352ms/step - loss: 0.0170 - accuracy: 0.9964 - val_loss: 0.0977 - val_accuracy: 0.9527\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9595\n",
            "31/31 [==============================] - 4s 113ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 376ms/step - loss: 0.6255 - accuracy: 0.6727 - val_loss: 0.3831 - val_accuracy: 0.8581\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 313ms/step - loss: 0.3065 - accuracy: 0.9125 - val_loss: 0.1454 - val_accuracy: 0.9324\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 1.9643 - accuracy: 0.6535 - val_loss: 0.3894 - val_accuracy: 0.8514\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 368ms/step - loss: 0.1970 - accuracy: 0.9712 - val_loss: 0.1577 - val_accuracy: 0.9459\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.0712 - accuracy: 0.9880 - val_loss: 0.1247 - val_accuracy: 0.9527\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 318ms/step - loss: 0.0456 - accuracy: 0.9916 - val_loss: 0.1129 - val_accuracy: 0.9595\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.0316 - accuracy: 0.9928 - val_loss: 0.0990 - val_accuracy: 0.9595\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.0216 - accuracy: 0.9964 - val_loss: 0.1262 - val_accuracy: 0.9459\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 342ms/step - loss: 0.0230 - accuracy: 0.9976 - val_loss: 0.1129 - val_accuracy: 0.9595\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 315ms/step - loss: 0.0140 - accuracy: 0.9976 - val_loss: 0.1198 - val_accuracy: 0.9595\n",
            "31/31 [==============================] - 4s 123ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 370ms/step - loss: 0.6054 - accuracy: 0.6942 - val_loss: 0.4056 - val_accuracy: 0.8176\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 315ms/step - loss: 0.2281 - accuracy: 0.9089 - val_loss: 0.1237 - val_accuracy: 0.9527\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 367ms/step - loss: 0.0855 - accuracy: 0.9784 - val_loss: 0.1154 - val_accuracy: 0.9595\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 9s 353ms/step - loss: 0.0536 - accuracy: 0.9856 - val_loss: 0.1174 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 331ms/step - loss: 0.0300 - accuracy: 0.9892 - val_loss: 0.0963 - val_accuracy: 0.9595\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 329ms/step - loss: 0.0182 - accuracy: 0.9964 - val_loss: 0.1073 - val_accuracy: 0.9662\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.0183 - accuracy: 0.9916 - val_loss: 0.0906 - val_accuracy: 0.9662\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9662\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 310ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.1070 - val_accuracy: 0.9662\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.1093 - val_accuracy: 0.9662\n",
            "31/31 [==============================] - 5s 137ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 368ms/step - loss: 0.6222 - accuracy: 0.6942 - val_loss: 0.4037 - val_accuracy: 0.8311\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 312ms/step - loss: 1.4509 - accuracy: 0.7554 - val_loss: 1.6249 - val_accuracy: 0.5338\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.8422 - accuracy: 0.6391 - val_loss: 0.5314 - val_accuracy: 0.7635\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.4243 - accuracy: 0.8945 - val_loss: 0.4510 - val_accuracy: 0.7905\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 329ms/step - loss: 0.3074 - accuracy: 0.9400 - val_loss: 0.3947 - val_accuracy: 0.8311\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 330ms/step - loss: 0.2230 - accuracy: 0.9700 - val_loss: 0.3535 - val_accuracy: 0.8649\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.1614 - accuracy: 0.9820 - val_loss: 0.3242 - val_accuracy: 0.8716\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.1191 - accuracy: 0.9928 - val_loss: 0.2975 - val_accuracy: 0.8784\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 304ms/step - loss: 0.0880 - accuracy: 0.9952 - val_loss: 0.2759 - val_accuracy: 0.8851\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 0.0667 - accuracy: 0.9988 - val_loss: 0.2524 - val_accuracy: 0.8986\n",
            "31/31 [==============================] - 3s 94ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 332ms/step - loss: 0.5931 - accuracy: 0.7050 - val_loss: 0.4162 - val_accuracy: 0.8446\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 10s 352ms/step - loss: 0.2233 - accuracy: 0.9185 - val_loss: 0.1280 - val_accuracy: 0.9595\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 1.8277 - accuracy: 0.7446 - val_loss: 0.9187 - val_accuracy: 0.7635\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 368ms/step - loss: 0.7884 - accuracy: 0.7050 - val_loss: 0.3687 - val_accuracy: 0.8649\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 317ms/step - loss: 0.2864 - accuracy: 0.9209 - val_loss: 0.2753 - val_accuracy: 0.9054\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.1901 - accuracy: 0.9604 - val_loss: 0.2137 - val_accuracy: 0.9257\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.1326 - accuracy: 0.9772 - val_loss: 0.1824 - val_accuracy: 0.9324\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 368ms/step - loss: 0.1033 - accuracy: 0.9856 - val_loss: 0.2019 - val_accuracy: 0.9054\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.1015 - accuracy: 0.9760 - val_loss: 0.1841 - val_accuracy: 0.9459\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 367ms/step - loss: 0.0810 - accuracy: 0.9772 - val_loss: 0.2457 - val_accuracy: 0.9257\n",
            "31/31 [==============================] - 3s 97ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 356ms/step - loss: 0.6066 - accuracy: 0.7686 - val_loss: 0.4366 - val_accuracy: 0.8176\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 322ms/step - loss: 0.2746 - accuracy: 0.9257 - val_loss: 0.1915 - val_accuracy: 0.9392\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.1029 - accuracy: 0.9700 - val_loss: 0.1422 - val_accuracy: 0.9527\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.0540 - accuracy: 0.9904 - val_loss: 0.0877 - val_accuracy: 0.9662\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 8s 313ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 0.0910 - val_accuracy: 0.9662\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 353ms/step - loss: 0.0172 - accuracy: 0.9988 - val_loss: 0.0769 - val_accuracy: 0.9459\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.0166 - accuracy: 0.9964 - val_loss: 0.0848 - val_accuracy: 0.9662\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 375ms/step - loss: 0.0208 - accuracy: 0.9964 - val_loss: 0.2464 - val_accuracy: 0.8716\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 312ms/step - loss: 0.0872 - accuracy: 0.9628 - val_loss: 0.1846 - val_accuracy: 0.8986\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.0279 - accuracy: 0.9988 - val_loss: 0.1414 - val_accuracy: 0.9257\n",
            "31/31 [==============================] - 5s 135ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 374ms/step - loss: 0.6230 - accuracy: 0.7074 - val_loss: 0.4308 - val_accuracy: 0.8514\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 307ms/step - loss: 0.2510 - accuracy: 0.9125 - val_loss: 0.1494 - val_accuracy: 0.9459\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.0837 - accuracy: 0.9748 - val_loss: 0.1314 - val_accuracy: 0.9459\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2330 - accuracy: 0.9568 - val_loss: 0.1752 - val_accuracy: 0.9189\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 351ms/step - loss: 0.0644 - accuracy: 0.9844 - val_loss: 0.1625 - val_accuracy: 0.9257\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 313ms/step - loss: 0.0454 - accuracy: 0.9856 - val_loss: 0.1489 - val_accuracy: 0.9257\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0300 - accuracy: 0.9904 - val_loss: 0.1582 - val_accuracy: 0.9189\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 367ms/step - loss: 0.0239 - accuracy: 0.9904 - val_loss: 0.1506 - val_accuracy: 0.9189\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 316ms/step - loss: 0.0184 - accuracy: 0.9904 - val_loss: 0.1626 - val_accuracy: 0.9189\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 337ms/step - loss: 0.0149 - accuracy: 0.9928 - val_loss: 0.1620 - val_accuracy: 0.9324\n",
            "31/31 [==============================] - 4s 127ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 373ms/step - loss: 0.6028 - accuracy: 0.7230 - val_loss: 0.3530 - val_accuracy: 0.8446\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 315ms/step - loss: 0.2254 - accuracy: 0.9149 - val_loss: 0.2814 - val_accuracy: 0.8919\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 344ms/step - loss: 0.2121 - accuracy: 0.9365 - val_loss: 0.2101 - val_accuracy: 0.8986\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0798 - accuracy: 0.9808 - val_loss: 0.1294 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 0.1374 - val_accuracy: 0.9392\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 8s 305ms/step - loss: 0.0325 - accuracy: 0.9892 - val_loss: 0.1280 - val_accuracy: 0.9392\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.0989 - val_accuracy: 0.9527\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 367ms/step - loss: 0.0192 - accuracy: 0.9916 - val_loss: 0.1200 - val_accuracy: 0.9459\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 337ms/step - loss: 0.0140 - accuracy: 0.9928 - val_loss: 0.1348 - val_accuracy: 0.9595\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 326ms/step - loss: 0.0147 - accuracy: 0.9928 - val_loss: 0.0905 - val_accuracy: 0.9730\n",
            "31/31 [==============================] - 5s 139ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 376ms/step - loss: 0.6160 - accuracy: 0.7518 - val_loss: 0.4391 - val_accuracy: 0.8108\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 324ms/step - loss: 0.2461 - accuracy: 0.9149 - val_loss: 0.1472 - val_accuracy: 0.9527\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.0880 - accuracy: 0.9796 - val_loss: 0.1729 - val_accuracy: 0.9392\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.0635 - accuracy: 0.9808 - val_loss: 0.1189 - val_accuracy: 0.9392\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0493 - accuracy: 0.9856 - val_loss: 0.1169 - val_accuracy: 0.9459\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.0219 - accuracy: 0.9904 - val_loss: 0.1175 - val_accuracy: 0.9324\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.0186 - accuracy: 0.9952 - val_loss: 0.1206 - val_accuracy: 0.9595\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0124 - accuracy: 0.9952 - val_loss: 0.1192 - val_accuracy: 0.9527\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.1046 - val_accuracy: 0.9662\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 339ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.1196 - val_accuracy: 0.9595\n",
            "31/31 [==============================] - 4s 105ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 382ms/step - loss: 0.6171 - accuracy: 0.7206 - val_loss: 0.4282 - val_accuracy: 0.8581\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 317ms/step - loss: 1.2288 - accuracy: 0.8273 - val_loss: 3.2483 - val_accuracy: 0.5338\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 1.0099 - accuracy: 0.7674 - val_loss: 0.2948 - val_accuracy: 0.8986\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 368ms/step - loss: 0.2223 - accuracy: 0.9568 - val_loss: 0.2324 - val_accuracy: 0.9122\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 342ms/step - loss: 0.1093 - accuracy: 0.9808 - val_loss: 0.1164 - val_accuracy: 0.9662\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 319ms/step - loss: 0.0600 - accuracy: 0.9916 - val_loss: 0.1146 - val_accuracy: 0.9662\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 367ms/step - loss: 0.0368 - accuracy: 0.9976 - val_loss: 0.0883 - val_accuracy: 0.9730\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 368ms/step - loss: 0.0261 - accuracy: 0.9964 - val_loss: 0.0933 - val_accuracy: 0.9595\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 342ms/step - loss: 0.0226 - accuracy: 0.9976 - val_loss: 0.1032 - val_accuracy: 0.9595\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 325ms/step - loss: 0.0173 - accuracy: 0.9964 - val_loss: 0.0996 - val_accuracy: 0.9595\n",
            "31/31 [==============================] - 4s 132ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 377ms/step - loss: 0.6050 - accuracy: 0.7218 - val_loss: 0.4168 - val_accuracy: 0.8581\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 316ms/step - loss: 0.2466 - accuracy: 0.9221 - val_loss: 0.1285 - val_accuracy: 0.9595\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 364ms/step - loss: 1.6469 - accuracy: 0.7794 - val_loss: 3.1180 - val_accuracy: 0.5135\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 2.2689 - accuracy: 0.5204 - val_loss: 1.6162 - val_accuracy: 0.5135\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 1.2380 - accuracy: 0.5204 - val_loss: 0.9417 - val_accuracy: 0.5135\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 8s 313ms/step - loss: 0.7852 - accuracy: 0.5204 - val_loss: 0.6995 - val_accuracy: 0.5135\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 367ms/step - loss: 0.6372 - accuracy: 0.5516 - val_loss: 0.6135 - val_accuracy: 0.6351\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.5557 - accuracy: 0.7086 - val_loss: 0.5263 - val_accuracy: 0.7162\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 349ms/step - loss: 0.4526 - accuracy: 0.7878 - val_loss: 0.4208 - val_accuracy: 0.8041\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 8s 306ms/step - loss: 0.3583 - accuracy: 0.8585 - val_loss: 0.3352 - val_accuracy: 0.8311\n",
            "31/31 [==============================] - 4s 105ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 375ms/step - loss: 0.6227 - accuracy: 0.7458 - val_loss: 0.3662 - val_accuracy: 0.8378\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 354ms/step - loss: 0.2694 - accuracy: 0.9388 - val_loss: 0.1609 - val_accuracy: 0.9595\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 8s 303ms/step - loss: 0.0998 - accuracy: 0.9712 - val_loss: 0.1306 - val_accuracy: 0.9257\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 9s 350ms/step - loss: 0.0713 - accuracy: 0.9796 - val_loss: 0.1199 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 349ms/step - loss: 0.0404 - accuracy: 0.9856 - val_loss: 0.0897 - val_accuracy: 0.9730\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 365ms/step - loss: 0.0235 - accuracy: 0.9940 - val_loss: 0.0694 - val_accuracy: 0.9797\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 0.0768 - val_accuracy: 0.9730\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.0781 - val_accuracy: 0.9730\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 351ms/step - loss: 0.0134 - accuracy: 0.9976 - val_loss: 0.0658 - val_accuracy: 0.9797\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0111 - accuracy: 0.9952 - val_loss: 0.0692 - val_accuracy: 0.9730\n",
            "31/31 [==============================] - 4s 94ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 349ms/step - loss: 0.6122 - accuracy: 0.7446 - val_loss: 0.4939 - val_accuracy: 0.7905\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 354ms/step - loss: 0.2964 - accuracy: 0.8957 - val_loss: 0.1683 - val_accuracy: 0.9122\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 348ms/step - loss: 0.0824 - accuracy: 0.9760 - val_loss: 0.1239 - val_accuracy: 0.9595\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 8s 311ms/step - loss: 0.3342 - accuracy: 0.9412 - val_loss: 0.1852 - val_accuracy: 0.8986\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.1330 - accuracy: 0.9544 - val_loss: 0.1538 - val_accuracy: 0.9257\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0635 - accuracy: 0.9856 - val_loss: 0.1097 - val_accuracy: 0.9662\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0298 - accuracy: 0.9904 - val_loss: 0.1034 - val_accuracy: 0.9595\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 8s 312ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.1014 - val_accuracy: 0.9662\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 354ms/step - loss: 0.0153 - accuracy: 0.9988 - val_loss: 0.0992 - val_accuracy: 0.9662\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0221 - accuracy: 0.9952 - val_loss: 0.1040 - val_accuracy: 0.9662\n",
            "31/31 [==============================] - 3s 95ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 366ms/step - loss: 0.6031 - accuracy: 0.7302 - val_loss: 0.3383 - val_accuracy: 0.8581\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 349ms/step - loss: 0.2382 - accuracy: 0.9281 - val_loss: 0.1471 - val_accuracy: 0.9122\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 11s 401ms/step - loss: 0.8506 - accuracy: 0.8477 - val_loss: 0.3660 - val_accuracy: 0.8446\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 8s 301ms/step - loss: 0.1944 - accuracy: 0.9568 - val_loss: 0.2024 - val_accuracy: 0.9459\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 350ms/step - loss: 0.0893 - accuracy: 0.9772 - val_loss: 0.1391 - val_accuracy: 0.9459\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 350ms/step - loss: 0.0528 - accuracy: 0.9892 - val_loss: 0.1099 - val_accuracy: 0.9527\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0355 - accuracy: 0.9904 - val_loss: 0.1028 - val_accuracy: 0.9595\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 8s 312ms/step - loss: 0.0261 - accuracy: 0.9940 - val_loss: 0.0938 - val_accuracy: 0.9595\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0208 - accuracy: 0.9976 - val_loss: 0.1200 - val_accuracy: 0.9527\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 354ms/step - loss: 0.0168 - accuracy: 0.9964 - val_loss: 0.1019 - val_accuracy: 0.9527\n",
            "31/31 [==============================] - 3s 95ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 364ms/step - loss: 0.6209 - accuracy: 0.7338 - val_loss: 0.4703 - val_accuracy: 0.7973\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 344ms/step - loss: 0.2696 - accuracy: 0.9041 - val_loss: 0.1652 - val_accuracy: 0.9662\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 336ms/step - loss: 0.5957 - accuracy: 0.9149 - val_loss: 0.1375 - val_accuracy: 0.9527\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 8s 299ms/step - loss: 0.1472 - accuracy: 0.9688 - val_loss: 0.1632 - val_accuracy: 0.9527\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 344ms/step - loss: 0.0799 - accuracy: 0.9796 - val_loss: 0.1341 - val_accuracy: 0.9595\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 347ms/step - loss: 0.0411 - accuracy: 0.9868 - val_loss: 0.1280 - val_accuracy: 0.9527\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 8s 308ms/step - loss: 0.0276 - accuracy: 0.9928 - val_loss: 0.1198 - val_accuracy: 0.9527\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 9s 354ms/step - loss: 0.0217 - accuracy: 0.9964 - val_loss: 0.1183 - val_accuracy: 0.9595\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 351ms/step - loss: 0.0157 - accuracy: 0.9964 - val_loss: 0.1229 - val_accuracy: 0.9527\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 343ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.1329 - val_accuracy: 0.9527\n",
            "31/31 [==============================] - 3s 94ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 374ms/step - loss: 0.6162 - accuracy: 0.6954 - val_loss: 0.4151 - val_accuracy: 0.8243\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 315ms/step - loss: 0.2277 - accuracy: 0.9293 - val_loss: 0.1291 - val_accuracy: 0.9527\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 350ms/step - loss: 1.2604 - accuracy: 0.7554 - val_loss: 1.0582 - val_accuracy: 0.6486\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2818 - accuracy: 0.8885 - val_loss: 0.1962 - val_accuracy: 0.9459\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 331ms/step - loss: 0.1618 - accuracy: 0.9652 - val_loss: 0.1533 - val_accuracy: 0.9392\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 320ms/step - loss: 0.1204 - accuracy: 0.9700 - val_loss: 0.1375 - val_accuracy: 0.9392\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.1012 - accuracy: 0.9796 - val_loss: 0.1240 - val_accuracy: 0.9392\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0872 - accuracy: 0.9820 - val_loss: 0.1154 - val_accuracy: 0.9392\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 311ms/step - loss: 0.0779 - accuracy: 0.9832 - val_loss: 0.1095 - val_accuracy: 0.9459\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 340ms/step - loss: 0.0713 - accuracy: 0.9868 - val_loss: 0.1058 - val_accuracy: 0.9459\n",
            "31/31 [==============================] - 4s 114ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 342ms/step - loss: 0.5996 - accuracy: 0.7446 - val_loss: 0.4874 - val_accuracy: 0.7297\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 320ms/step - loss: 0.2556 - accuracy: 0.9017 - val_loss: 0.1462 - val_accuracy: 0.9459\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.1004 - accuracy: 0.9748 - val_loss: 0.1316 - val_accuracy: 0.9459\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0551 - accuracy: 0.9808 - val_loss: 0.1518 - val_accuracy: 0.9392\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 8s 304ms/step - loss: 0.0433 - accuracy: 0.9844 - val_loss: 0.1303 - val_accuracy: 0.9459\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0282 - accuracy: 0.9892 - val_loss: 0.1327 - val_accuracy: 0.9459\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.0180 - accuracy: 0.9916 - val_loss: 0.1323 - val_accuracy: 0.9257\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.1304 - val_accuracy: 0.9392\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 312ms/step - loss: 0.0093 - accuracy: 0.9988 - val_loss: 0.1228 - val_accuracy: 0.9527\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.1392 - val_accuracy: 0.9527\n",
            "31/31 [==============================] - 4s 108ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 364ms/step - loss: 0.6295 - accuracy: 0.7002 - val_loss: 0.4730 - val_accuracy: 0.7635\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 313ms/step - loss: 0.2464 - accuracy: 0.9161 - val_loss: 0.1336 - val_accuracy: 0.9459\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 335ms/step - loss: 1.0768 - accuracy: 0.7698 - val_loss: 0.3116 - val_accuracy: 0.8581\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.1887 - accuracy: 0.9197 - val_loss: 0.1916 - val_accuracy: 0.9122\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 349ms/step - loss: 0.1090 - accuracy: 0.9520 - val_loss: 0.1544 - val_accuracy: 0.9257\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 8s 310ms/step - loss: 0.0832 - accuracy: 0.9712 - val_loss: 0.1181 - val_accuracy: 0.9595\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0513 - accuracy: 0.9904 - val_loss: 0.1226 - val_accuracy: 0.9459\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0433 - accuracy: 0.9880 - val_loss: 0.1278 - val_accuracy: 0.9392\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 354ms/step - loss: 0.0372 - accuracy: 0.9976 - val_loss: 0.1080 - val_accuracy: 0.9662\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 8s 307ms/step - loss: 0.0229 - accuracy: 0.9988 - val_loss: 0.0647 - val_accuracy: 0.9730\n",
            "31/31 [==============================] - 4s 134ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 374ms/step - loss: 0.5900 - accuracy: 0.7098 - val_loss: 0.3837 - val_accuracy: 0.8446\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 304ms/step - loss: 0.2124 - accuracy: 0.9281 - val_loss: 0.1396 - val_accuracy: 0.9527\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 342ms/step - loss: 0.0779 - accuracy: 0.9760 - val_loss: 0.1325 - val_accuracy: 0.9392\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.0398 - accuracy: 0.9856 - val_loss: 0.1296 - val_accuracy: 0.9392\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 346ms/step - loss: 0.0333 - accuracy: 0.9916 - val_loss: 0.1061 - val_accuracy: 0.9595\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 8s 311ms/step - loss: 0.0243 - accuracy: 0.9976 - val_loss: 0.1034 - val_accuracy: 0.9595\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 9s 344ms/step - loss: 0.0131 - accuracy: 0.9940 - val_loss: 0.1032 - val_accuracy: 0.9662\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0263 - accuracy: 0.9964 - val_loss: 0.1435 - val_accuracy: 0.9527\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 337ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9662\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 309ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1128 - val_accuracy: 0.9595\n",
            "31/31 [==============================] - 3s 95ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 13s 399ms/step - loss: 0.6013 - accuracy: 0.7434 - val_loss: 0.3268 - val_accuracy: 0.8919\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 352ms/step - loss: 0.2066 - accuracy: 0.9388 - val_loss: 0.1545 - val_accuracy: 0.9324\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 379ms/step - loss: 0.0878 - accuracy: 0.9748 - val_loss: 0.1048 - val_accuracy: 0.9527\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0460 - accuracy: 0.9844 - val_loss: 0.0885 - val_accuracy: 0.9730\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 332ms/step - loss: 0.0290 - accuracy: 0.9916 - val_loss: 0.0758 - val_accuracy: 0.9730\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0864 - val_accuracy: 0.9662\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0350 - accuracy: 0.9916 - val_loss: 0.2357 - val_accuracy: 0.8986\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 8s 313ms/step - loss: 0.0619 - accuracy: 0.9892 - val_loss: 0.0918 - val_accuracy: 0.9662\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.0341 - accuracy: 0.9964 - val_loss: 0.0474 - val_accuracy: 0.9865\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 351ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.0770 - val_accuracy: 0.9662\n",
            "31/31 [==============================] - 3s 98ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 11s 323ms/step - loss: 0.7130 - accuracy: 0.6894 - val_loss: 0.4699 - val_accuracy: 0.7770\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.3787 - accuracy: 0.8717 - val_loss: 0.2683 - val_accuracy: 0.9324\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 351ms/step - loss: 0.1703 - accuracy: 0.9376 - val_loss: 0.1481 - val_accuracy: 0.9595\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.0801 - accuracy: 0.9796 - val_loss: 0.1216 - val_accuracy: 0.9527\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 8s 315ms/step - loss: 0.0477 - accuracy: 0.9820 - val_loss: 0.1041 - val_accuracy: 0.9595\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0328 - accuracy: 0.9880 - val_loss: 0.1045 - val_accuracy: 0.9595\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.0357 - accuracy: 0.9892 - val_loss: 0.1048 - val_accuracy: 0.9459\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 9s 349ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9527\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 303ms/step - loss: 0.0152 - accuracy: 0.9988 - val_loss: 0.1066 - val_accuracy: 0.9527\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.0305 - accuracy: 0.9916 - val_loss: 0.1266 - val_accuracy: 0.9527\n",
            "31/31 [==============================] - 3s 96ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 363ms/step - loss: 0.6172 - accuracy: 0.6966 - val_loss: 0.3514 - val_accuracy: 0.8649\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 303ms/step - loss: 0.2323 - accuracy: 0.9221 - val_loss: 0.1716 - val_accuracy: 0.9392\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0831 - accuracy: 0.9820 - val_loss: 0.0972 - val_accuracy: 0.9730\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0437 - accuracy: 0.9892 - val_loss: 0.0690 - val_accuracy: 0.9797\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 316ms/step - loss: 0.0224 - accuracy: 0.9940 - val_loss: 0.0999 - val_accuracy: 0.9730\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 332ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.0816 - val_accuracy: 0.9730\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0146 - accuracy: 0.9988 - val_loss: 0.0500 - val_accuracy: 0.9865\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.0619 - val_accuracy: 0.9797\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 313ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.0673 - val_accuracy: 0.9797\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 336ms/step - loss: 0.0334 - accuracy: 0.9904 - val_loss: 0.0947 - val_accuracy: 0.9595\n",
            "31/31 [==============================] - 3s 96ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 366ms/step - loss: 0.6131 - accuracy: 0.7230 - val_loss: 0.4732 - val_accuracy: 0.7770\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.2682 - accuracy: 0.9089 - val_loss: 0.1498 - val_accuracy: 0.9527\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 347ms/step - loss: 0.0866 - accuracy: 0.9736 - val_loss: 0.1161 - val_accuracy: 0.9595\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.0467 - accuracy: 0.9844 - val_loss: 0.1131 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 351ms/step - loss: 0.0284 - accuracy: 0.9880 - val_loss: 0.1071 - val_accuracy: 0.9595\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 350ms/step - loss: 0.0210 - accuracy: 0.9916 - val_loss: 0.1076 - val_accuracy: 0.9527\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 9s 320ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.1338 - val_accuracy: 0.9459\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 9s 332ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 0.1053 - val_accuracy: 0.9595\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.1132 - val_accuracy: 0.9595\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.1547 - val_accuracy: 0.9459\n",
            "31/31 [==============================] - 3s 96ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 13s 368ms/step - loss: 0.6258 - accuracy: 0.6763 - val_loss: 0.4111 - val_accuracy: 0.8649\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.2662 - accuracy: 0.9245 - val_loss: 0.1570 - val_accuracy: 0.9459\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.1145 - accuracy: 0.9688 - val_loss: 0.1074 - val_accuracy: 0.9662\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 9s 351ms/step - loss: 0.0581 - accuracy: 0.9856 - val_loss: 0.0773 - val_accuracy: 0.9865\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 316ms/step - loss: 0.0282 - accuracy: 0.9916 - val_loss: 0.0820 - val_accuracy: 0.9730\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.0200 - accuracy: 0.9952 - val_loss: 0.0731 - val_accuracy: 0.9730\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0157 - accuracy: 0.9940 - val_loss: 0.0579 - val_accuracy: 0.9730\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 9s 338ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.0617 - val_accuracy: 0.9730\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 314ms/step - loss: 0.0103 - accuracy: 0.9952 - val_loss: 0.0515 - val_accuracy: 0.9730\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0539 - val_accuracy: 0.9730\n",
            "31/31 [==============================] - 3s 98ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 361ms/step - loss: 0.6213 - accuracy: 0.6667 - val_loss: 0.5333 - val_accuracy: 0.7162\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 8s 304ms/step - loss: 0.3594 - accuracy: 0.8705 - val_loss: 0.2119 - val_accuracy: 0.9257\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 349ms/step - loss: 0.1214 - accuracy: 0.9604 - val_loss: 0.1188 - val_accuracy: 0.9595\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.0623 - accuracy: 0.9808 - val_loss: 0.1021 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 8s 313ms/step - loss: 0.0401 - accuracy: 0.9856 - val_loss: 0.1392 - val_accuracy: 0.9459\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 332ms/step - loss: 0.0431 - accuracy: 0.9928 - val_loss: 0.1003 - val_accuracy: 0.9595\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 0.0853 - val_accuracy: 0.9662\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.0120 - accuracy: 0.9976 - val_loss: 0.0885 - val_accuracy: 0.9662\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.0876 - val_accuracy: 0.9662\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 361ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9595\n",
            "31/31 [==============================] - 3s 96ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 13s 419ms/step - loss: 0.6145 - accuracy: 0.6871 - val_loss: 0.3360 - val_accuracy: 0.8784\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2228 - accuracy: 0.9365 - val_loss: 4.8245 - val_accuracy: 0.5338\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 341ms/step - loss: 0.6559 - accuracy: 0.8777 - val_loss: 0.2394 - val_accuracy: 0.8986\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 8s 310ms/step - loss: 0.1227 - accuracy: 0.9472 - val_loss: 0.1185 - val_accuracy: 0.9527\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.0947 - accuracy: 0.9712 - val_loss: 0.1487 - val_accuracy: 0.9392\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 360ms/step - loss: 0.0506 - accuracy: 0.9916 - val_loss: 0.1022 - val_accuracy: 0.9595\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 9s 338ms/step - loss: 0.0295 - accuracy: 0.9952 - val_loss: 0.0863 - val_accuracy: 0.9662\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 9s 312ms/step - loss: 0.0223 - accuracy: 0.9964 - val_loss: 0.0896 - val_accuracy: 0.9662\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0182 - accuracy: 0.9964 - val_loss: 0.0749 - val_accuracy: 0.9595\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0158 - accuracy: 0.9976 - val_loss: 0.0820 - val_accuracy: 0.9595\n",
            "31/31 [==============================] - 3s 98ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 11s 322ms/step - loss: 0.5998 - accuracy: 0.7158 - val_loss: 0.3898 - val_accuracy: 0.8311\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.2049 - accuracy: 0.9245 - val_loss: 0.1347 - val_accuracy: 0.9527\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 347ms/step - loss: 0.4643 - accuracy: 0.9281 - val_loss: 0.1660 - val_accuracy: 0.9459\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.1025 - accuracy: 0.9676 - val_loss: 0.1276 - val_accuracy: 0.9527\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 8s 312ms/step - loss: 0.0583 - accuracy: 0.9820 - val_loss: 0.1106 - val_accuracy: 0.9595\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 350ms/step - loss: 0.0371 - accuracy: 0.9880 - val_loss: 0.1091 - val_accuracy: 0.9527\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 10s 362ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 0.1160 - val_accuracy: 0.9527\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0212 - accuracy: 0.9952 - val_loss: 0.0961 - val_accuracy: 0.9662\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 8s 305ms/step - loss: 0.0255 - accuracy: 0.9976 - val_loss: 0.1054 - val_accuracy: 0.9662\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9527\n",
            "31/31 [==============================] - 4s 129ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 13s 375ms/step - loss: 0.6239 - accuracy: 0.7242 - val_loss: 0.3856 - val_accuracy: 0.8581\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 351ms/step - loss: 0.2316 - accuracy: 0.9353 - val_loss: 0.1477 - val_accuracy: 0.9595\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 8s 311ms/step - loss: 0.1063 - accuracy: 0.9808 - val_loss: 0.1222 - val_accuracy: 0.9797\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 9s 350ms/step - loss: 0.0644 - accuracy: 0.9820 - val_loss: 0.0818 - val_accuracy: 0.9730\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 351ms/step - loss: 0.0332 - accuracy: 0.9892 - val_loss: 0.0645 - val_accuracy: 0.9797\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 8s 311ms/step - loss: 0.0195 - accuracy: 0.9928 - val_loss: 0.0636 - val_accuracy: 0.9797\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 9s 340ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.0538 - val_accuracy: 0.9797\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 363ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.0683 - val_accuracy: 0.9730\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.1106 - val_accuracy: 0.9662\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 8s 314ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9595\n",
            "31/31 [==============================] - 3s 98ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 368ms/step - loss: 0.6255 - accuracy: 0.7122 - val_loss: 0.4669 - val_accuracy: 0.8514\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2560 - accuracy: 0.9053 - val_loss: 0.1574 - val_accuracy: 0.9595\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 347ms/step - loss: 0.0890 - accuracy: 0.9736 - val_loss: 0.1119 - val_accuracy: 0.9595\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 8s 303ms/step - loss: 0.3697 - accuracy: 0.9520 - val_loss: 5.0483 - val_accuracy: 0.5135\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 347ms/step - loss: 2.7450 - accuracy: 0.5300 - val_loss: 0.6257 - val_accuracy: 0.7162\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.2449 - accuracy: 0.9113 - val_loss: 0.2351 - val_accuracy: 0.8986\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 8s 309ms/step - loss: 0.1835 - accuracy: 0.9376 - val_loss: 0.2004 - val_accuracy: 0.9122\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 9s 337ms/step - loss: 0.1264 - accuracy: 0.9556 - val_loss: 0.2138 - val_accuracy: 0.9257\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0973 - accuracy: 0.9652 - val_loss: 0.2129 - val_accuracy: 0.9257\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2417 - accuracy: 0.9101 - val_loss: 0.3271 - val_accuracy: 0.9527\n",
            "31/31 [==============================] - 3s 96ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 372ms/step - loss: 0.6331 - accuracy: 0.6523 - val_loss: 0.4595 - val_accuracy: 0.8108\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 346ms/step - loss: 0.2539 - accuracy: 0.9197 - val_loss: 0.4048 - val_accuracy: 0.8311\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 10s 366ms/step - loss: 0.1241 - accuracy: 0.9604 - val_loss: 0.1264 - val_accuracy: 0.9662\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 8s 302ms/step - loss: 0.0510 - accuracy: 0.9856 - val_loss: 0.0673 - val_accuracy: 0.9797\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 0.0628 - val_accuracy: 0.9730\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 351ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.0590 - val_accuracy: 0.9797\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 9s 345ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.0531 - val_accuracy: 0.9797\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 8s 310ms/step - loss: 0.0106 - accuracy: 0.9952 - val_loss: 0.0494 - val_accuracy: 0.9797\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.0457 - val_accuracy: 0.9797\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 9s 348ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.0576 - val_accuracy: 0.9797\n",
            "31/31 [==============================] - 3s 97ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 368ms/step - loss: 0.6023 - accuracy: 0.6859 - val_loss: 0.4218 - val_accuracy: 0.8176\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.2240 - accuracy: 0.9125 - val_loss: 0.1436 - val_accuracy: 0.9459\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 337ms/step - loss: 0.0804 - accuracy: 0.9772 - val_loss: 0.1145 - val_accuracy: 0.9527\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 8s 303ms/step - loss: 0.0684 - accuracy: 0.9796 - val_loss: 0.1238 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 9s 349ms/step - loss: 0.0501 - accuracy: 0.9856 - val_loss: 0.1123 - val_accuracy: 0.9527\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 10s 354ms/step - loss: 0.0229 - accuracy: 0.9916 - val_loss: 0.1174 - val_accuracy: 0.9459\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 8s 311ms/step - loss: 0.0176 - accuracy: 0.9964 - val_loss: 0.1112 - val_accuracy: 0.9595\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 10s 349ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.1183 - val_accuracy: 0.9595\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 355ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.1275 - val_accuracy: 0.9595\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 356ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9595\n",
            "31/31 [==============================] - 3s 98ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 13s 377ms/step - loss: 0.6168 - accuracy: 0.6990 - val_loss: 0.3763 - val_accuracy: 0.8851\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.2652 - accuracy: 0.9353 - val_loss: 0.2364 - val_accuracy: 0.9527\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 336ms/step - loss: 0.1500 - accuracy: 0.9652 - val_loss: 0.1301 - val_accuracy: 0.9595\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 9s 307ms/step - loss: 0.0703 - accuracy: 0.9784 - val_loss: 0.0993 - val_accuracy: 0.9865\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 358ms/step - loss: 0.0375 - accuracy: 0.9904 - val_loss: 0.0655 - val_accuracy: 0.9865\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 11s 398ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.0570 - val_accuracy: 0.9865\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 9s 335ms/step - loss: 0.0167 - accuracy: 0.9928 - val_loss: 0.0583 - val_accuracy: 0.9797\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 9s 309ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0516 - val_accuracy: 0.9797\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 9s 347ms/step - loss: 0.0106 - accuracy: 0.9988 - val_loss: 0.0472 - val_accuracy: 0.9797\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 359ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0576 - val_accuracy: 0.9730\n",
            "31/31 [==============================] - 3s 98ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 369ms/step - loss: 0.6085 - accuracy: 0.6727 - val_loss: 0.4115 - val_accuracy: 0.8243\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 348ms/step - loss: 0.2198 - accuracy: 0.9185 - val_loss: 0.1403 - val_accuracy: 0.9459\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 9s 335ms/step - loss: 0.0898 - accuracy: 0.9796 - val_loss: 0.1243 - val_accuracy: 0.9527\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 9s 317ms/step - loss: 0.0459 - accuracy: 0.9832 - val_loss: 0.1300 - val_accuracy: 0.9527\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0416 - accuracy: 0.9868 - val_loss: 0.0964 - val_accuracy: 0.9595\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 9s 349ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 0.1105 - val_accuracy: 0.9662\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 8s 311ms/step - loss: 0.0125 - accuracy: 0.9976 - val_loss: 0.1570 - val_accuracy: 0.9392\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 9s 342ms/step - loss: 0.0129 - accuracy: 0.9952 - val_loss: 0.1043 - val_accuracy: 0.9662\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9730\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 10s 357ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.1497 - val_accuracy: 0.9459\n",
            "31/31 [==============================] - 3s 97ms/step\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 12s 356ms/step - loss: 0.6065 - accuracy: 0.7086 - val_loss: 0.3989 - val_accuracy: 0.8176\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 9s 311ms/step - loss: 0.2300 - accuracy: 0.9329 - val_loss: 5.0847 - val_accuracy: 0.5338\n",
            "Epoch 3/10\n",
            "19/27 [====================>.........] - ETA: 2s - loss: 3.5982 - accuracy: 0.5247"
          ]
        }
      ],
      "source": [
        "param_grid={\n",
        "    'optimizer':['Adam'],\n",
        "    'feature_num':[50, 100, 200],\n",
        "    'mem_cells':[64, 128, 256],\n",
        "    'learning_rate':[0.001, 0.01, 0.0001],\n",
        "    'dropout_rate':[0.2, 0.5, 0.8],\n",
        "    'sentence_len':[150, 200]\n",
        "}\n",
        "\n",
        "keras_model = KerasClassifierWrapper()\n",
        "\n",
        "grid = GridSearchCV(estimator=keras_model, param_grid=param_grid, cv=2, scoring='accuracy')\n",
        "grid_result = grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqrzwH__e0iZ"
      },
      "outputs": [],
      "source": [
        "model = KerasClassifier(model=lstm_model, epochs=10, batch_size=10, verbose=0)\n",
        "# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "optimizer = ['Adam']\n",
        "feature_num=[50, 100, 200]\n",
        "mem_cells=[64, 128, 256]\n",
        "sentence_len=[150, 200]\n",
        "\n",
        "param_grid = dict(\n",
        "    model__optimizer=optimizer,\n",
        "    model__feature_num=feature_num,\n",
        "    model__sentence_len=sentence_len,\n",
        "    model__mem_cells=mem_cells,\n",
        "    model__learning_rate=learning_rate,\n",
        "    model__dropout_rate=dropout_rate\n",
        "    )\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train, error_score='raise')\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvHcFOFTgjmQ"
      },
      "outputs": [],
      "source": [
        "batch_size = [10, 20, 40, 60, 80, 100]\n",
        "epochs = [10, 50, 100]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
